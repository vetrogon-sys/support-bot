spring:
  application:
    name: demo
  ai:
    ollama:
      enabled: true
      model: llama3
      base-url: http://localhost:11434
      chat:
        options:
          model: llama3

crawler:
  inputFile: "./data/links.txt"
  outputDir: "./data-lake"

chunk:
  hash:
    algo: "SHA-256"

ollama:
  url: http://127.0.0.1:11434
  model:
    chat: "llama3.2:1b"
    embedding: "mxbai-embed-large"

vectorizer:
  embeddingModel: "mxbai-embed-large"
  collectionName: "support-chunks"
  ollamaBaseUrl: "http://127.0.0.1:11434"
  qdrantUrl: "http://127.0.0.1:6333"
  vectorSize: 384
